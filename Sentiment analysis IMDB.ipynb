{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def review_to_wordlist(review):\n",
    "    review_text = BeautifulSoup(review).get_text()\n",
    "    review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n",
    "    words = review_text.lower().split()\n",
    "    return(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('Individual assaignment data mining/Gegeven dataset/labeledTrainData.tsv', header=0,\n",
    "                delimiter=\"\\t\", quoting=3)\n",
    "test = pd.read_csv('Individual assaignment data mining/Gegeven dataset/testData.tsv', header=0, delimiter=\"\\t\",\n",
    "               quoting=3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train = train['sentiment']\n",
    "X_train = train['review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gladwellacademy/anaconda/lib/python3.6/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file /Users/gladwellacademy/anaconda/lib/python3.6/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "traindata = []\n",
    "for i in range(0,len(X_train)):\n",
    "    traindata.append(\" \".join(review_to_wordlist(X_train[i])))\n",
    "testdata = []\n",
    "for i in range(0,len(X_train)):\n",
    "    testdata.append(\" \".join(review_to_wordlist(X_train[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def tfidf(X_train = None, X_test = None, ngram_range = (1 ,2)):\n",
    "    if ngram_range:\n",
    "        ngram_range = ngram_range\n",
    "    else:\n",
    "        ngram_range = (1 ,2)\n",
    "        \n",
    "    tfv = TfidfVectorizer(min_df=3,  max_features=None,\n",
    "            strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n",
    "            ngram_range=ngram_range, use_idf=1,smooth_idf=1,sublinear_tf=1,\n",
    "            stop_words = 'english')\n",
    "    \n",
    "    if X_train:\n",
    "        Xfit = tfv.fit(X_train) \n",
    "        train = tfv.transform(X_train)\n",
    "    else: train = 'no training data provided'\n",
    "    if X_test:\n",
    "        Xtestfit = tfv.fit(X_test)\n",
    "        test = tfv.transform(X_test)\n",
    "    else: test = 'no testing data provided'\n",
    "    return(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_test = tfidf(X_train = traindata, X_test = testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "rvw_train, rvw_test, label_train, label_test = \\\n",
    "train_test_split(X_train, train['sentiment'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gladwellacademy/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/gladwellacademy/anaconda/lib/python3.6/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.grid_search import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=20, error_score='raise',\n",
       "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='L2', random_state=0, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid=[{'dual': [False], 'penalty': ['l1'], 'C': [1, 10]}, {'dual': [True], 'penalty': ['l2'], 'C': [1, 10, 100]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = [{'dual': [False], 'penalty': ['l1'], 'C': [1, 10]}, \n",
    "              {'dual': [True], 'penalty':['l2'], 'C': [1, 10 ,100]}]\n",
    "\n",
    "model_LR = GridSearchCV(LogisticRegression(penalty = 'L2', dual = True, random_state = 0), \n",
    "                        param_grid, scoring = 'roc_auc', cv = 20) \n",
    "                        \n",
    "model_LR.fit(rvw_train,label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.90      0.89      2410\n",
      "          1       0.90      0.88      0.89      2590\n",
      "\n",
      "avg / total       0.89      0.89      0.89      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "predictionsLR = model_LR.predict(rvw_test)\n",
    "print (classification_report(predictionsLR, label_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, class_weight=None, dual=True, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
       "          penalty='l2', random_state=0, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_LR_best = model_LR.best_estimator_\n",
    "model_LR_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinominal Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_MNB = MultinomialNB()\n",
    "model_MNB.fit(rvw_train,label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.87      0.87      2496\n",
      "          1       0.87      0.88      0.87      2504\n",
      "\n",
      "avg / total       0.87      0.87      0.87      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictionsMNB = model_MNB.predict(rvw_test)\n",
    "print (classification_report(predictionsMNB, label_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=20, error_score='raise',\n",
       "       estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=1,\n",
       "       penalty='l2', power_t=0.5, random_state=0, shuffle=True, verbose=0,\n",
       "       warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'alpha': [6e-05, 7e-05, 8e-05, 0.0001, 0.0005]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_params = {'alpha': [0.00006, 0.00007, 0.00008, 0.0001, 0.0005]} \n",
    "\n",
    "model_SGD = GridSearchCV(SGDClassifier(random_state = 0, shuffle = True, loss = 'modified_huber'), \n",
    "                        sgd_params, scoring = 'roc_auc', cv = 20)\n",
    "\n",
    "model_SGD.fit(rvw_train,label_train) \n",
    "\n",
    "predictionsSGD = model_SGD.predict(rvw_test)\n",
    "print (classification_report(predictionsSGD, label_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.90      0.89      2425\n",
      "          1       0.90      0.89      0.89      2575\n",
      "\n",
      "avg / total       0.89      0.89      0.89      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictionsSGD = model_SGD.predict(rvw_test)\n",
    "print (classification_report(predictionsSGD, label_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=1,\n",
       "       penalty='l2', power_t=0.5, random_state=0, shuffle=True, verbose=0,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_SGD_best = model_SGD.best_estimator_\n",
    "model_SGD_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forrest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=100, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'max_depth': [3, None], 'max_features': [1, 3, 10], 'min_samples_split': [2, 3, 10], 'min_samples_leaf': [1, 3, 10], 'bootstrap': [True, False], 'criterion': ['gini', 'entropy']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#use a large GridSearch over all parameters\n",
    "param_grid = {\"max_depth\": [3, None],\n",
    "              \"max_features\": [1, 3, 10],\n",
    "              \"min_samples_split\": [2, 3, 10],\n",
    "              \"min_samples_leaf\": [1, 3, 10],\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "#Run GridSearch and fitting model\n",
    "model_RFC = GridSearchCV(RandomForestClassifier(n_estimators = 100), param_grid=param_grid)\n",
    "\n",
    "model_RFC.fit(rvw_train,label_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.86      0.85      2412\n",
      "          1       0.87      0.85      0.86      2588\n",
      "\n",
      "avg / total       0.85      0.85      0.85      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictionsRFC = model_RFC.predict(rvw_test)\n",
    "print (classification_report(predictionsRFC, label_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=False, class_weight=None,\n",
       "            criterion='entropy', max_depth=None, max_features=10,\n",
       "            max_leaf_nodes=None, min_impurity_split=1e-07,\n",
       "            min_samples_leaf=1, min_samples_split=10,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_RFC_best = model_RFC.best_estimator_\n",
    "model_RFC_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def classifier(X_train, y, clf, predict = 'evaluate', X_test = None):\n",
    "    if predict == 'evaluate':\n",
    "        name = clf.__class__.__name__\n",
    "        rvw_train, rvw_test, label_train, label_test = \\\n",
    "        train_test_split(X_train, y, test_size=0.2) \n",
    "        clf.fit(rvw_train,label_train)\n",
    "        predictionsCLF = clf.predict(rvw_test)\n",
    "        print(name,\"\\n\", classification_report(predictionsCLF, label_test))\n",
    "    elif predict == 'submit':\n",
    "        clf.fit(X,y)\n",
    "        return clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.90      0.90      2439\n",
      "          1       0.91      0.89      0.90      2561\n",
      "\n",
      "avg / total       0.90      0.90      0.90      5000\n",
      "\n",
      "MultinomialNB \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.88      0.88      2522\n",
      "          1       0.88      0.87      0.87      2478\n",
      "\n",
      "avg / total       0.88      0.88      0.88      5000\n",
      "\n",
      "RandomForestClassifier \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.86      0.85      2437\n",
      "          1       0.86      0.85      0.86      2563\n",
      "\n",
      "avg / total       0.85      0.85      0.85      5000\n",
      "\n",
      "SGDClassifier \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.90      0.90      2522\n",
      "          1       0.90      0.90      0.90      2478\n",
      "\n",
      "avg / total       0.90      0.90      0.90      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Models based on best_estimator\n",
    "classifier(X_train, y_train, model_LR_best)\n",
    "classifier(X_train, y_train, model_MNB)\n",
    "classifier(X_train, y_train, model_RFC_best)\n",
    "classifier(X_train, y_train, model_SGD_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "weights = {'weights': [[1, 1, 1, 1],[2, 2, 2, 1],[2, 2, 1, 2],[2, 1, 2, 2],[3, 3, 2, 1]]} \n",
    "\n",
    "model_Voting1 = GridSearchCV(VotingClassifier(estimators=[('SGD', model_SGD_best), ('LR', model_LR_best),\n",
    "                                    ('MNB', model_MNB),('RFC', model_RFC_best)],\n",
    "                                    voting='soft'), weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Niet runnen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.91      0.90      2422\n",
      "          1       0.91      0.89      0.90      2578\n",
      "\n",
      "avg / total       0.90      0.90      0.90      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier(X_train, y_train, model_Voting1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('SGD', SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=1,\n",
       "       penalty='l2', power_t=0.5, random_state=0, shuffle=True, verbose=0,\n",
       "   ...n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False))],\n",
       "         n_jobs=1, voting='soft', weights=[3, 3, 2, 1])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_Voting1.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "weights = [[x, y, z] for x in range(4) for y in range(4) for z in range(4)]\n",
    "del [weights[weights.index([0,0,0])], weights[weights.index([1,1,1])], weights[weights.index([2,2,2])]]\n",
    "\n",
    "voting_weights = {'weights': weights}\n",
    "\n",
    "model_Voting2 = GridSearchCV(VotingClassifier(estimators=[('SGD', model_SGD), ('LR', model_LR),\n",
    "                                    ('MNB', model_MNB)],\n",
    "                                    voting='soft'), voting_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.90      0.90      2484\n",
      "          1       0.90      0.91      0.90      2516\n",
      "\n",
      "avg / total       0.90      0.90      0.90      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifier(X_train, y_train, model_Voting2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('SGD', GridSearchCV(cv=20, error_score='raise',\n",
       "       estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='modified_huber', n_iter=5, n_jobs=1,\n",
       "       penalty='l2',...scoring='roc_auc', verbose=0)), ('MNB', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
       "         n_jobs=1, voting='soft', weights=[3, 1, 2])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_Voting2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_3, X_test_3 = tfidf(X_train = traindata, X_test = testdata, ngram_range = (0, 3))\n",
    "\n",
    "rvw_train_3, rvw_test_3, label_train_3, label_test_3 = \\\n",
    "train_test_split(X_train_3, train['sentiment'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_4, X_test_4 = tfidf(X_train = traindata, X_test = testdata, ngram_range = (0, 4))\n",
    "\n",
    "rvw_train_4, rvw_test_4, label_train_4, label_test_4 = \\\n",
    "train_test_split(X_train_4, train['sentiment'], test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.91      0.90      2413\n",
      "          1       0.91      0.90      0.91      2587\n",
      "\n",
      "avg / total       0.90      0.90      0.90      5000\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.90      0.90      2509\n",
      "          1       0.90      0.90      0.90      2491\n",
      "\n",
      "avg / total       0.90      0.90      0.90      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_SGD = GridSearchCV(SGDClassifier(random_state = 0, shuffle = True, loss = 'modified_huber'), \n",
    "                        sgd_params, scoring = 'roc_auc', cv = 20)\n",
    "\n",
    "#Trigram\n",
    "model_SGD.fit(rvw_train_3,label_train_3) \n",
    "\n",
    "predictionsSGD = model_SGD.predict(rvw_test_3)\n",
    "print (classification_report(predictionsSGD, label_test_3))\n",
    "\n",
    "#Four-gram\n",
    "model_SGD.fit(rvw_train_4,label_train_4) \n",
    "\n",
    "predictionsSGD = model_SGD.predict(rvw_test_4)\n",
    "print (classification_report(predictionsSGD, label_test_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.91      0.90      2396\n",
      "          1       0.92      0.90      0.91      2604\n",
      "\n",
      "avg / total       0.90      0.90      0.90      5000\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.90      0.91      0.90      2484\n",
      "          1       0.91      0.90      0.90      2516\n",
      "\n",
      "avg / total       0.90      0.90      0.90      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid = [{'dual': [False], 'penalty': ['l1'], 'C': [1, 10]}, \n",
    "              {'dual': [True], 'penalty':['l2'], 'C': [1, 10 ,100]}]\n",
    "\n",
    "model_LR = GridSearchCV(LogisticRegression(penalty = 'L2', dual = True, random_state = 0), \n",
    "                        param_grid, scoring = 'roc_auc', cv = 20) \n",
    "                        \n",
    "#Trigram\n",
    "model_LR.fit(rvw_train_3,label_train_3)\n",
    "\n",
    "predictionsLR = model_LR.predict(rvw_test_3)\n",
    "print (classification_report(predictionsLR, label_test_3))\n",
    "\n",
    "#Four-gram\n",
    "model_LR.fit(rvw_train_4,label_train_4)\n",
    "\n",
    "predictionsLR = model_LR.predict(rvw_test_4)\n",
    "print (classification_report(predictionsLR, label_test_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
